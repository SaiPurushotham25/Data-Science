{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecb72d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Obtaining dependency information for openai from https://files.pythonhosted.org/packages/26/a1/75474477af2a1dae3a25f80b72bbaf20e8296191ece7fff2f67984206f33/openai-1.12.0-py3-none-any.whl.metadata\n",
      "  Downloading openai-1.12.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\anaconda\\lib\\site-packages (from openai) (3.5.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Obtaining dependency information for distro<2,>=1.7.0 from https://files.pythonhosted.org/packages/12/b3/231ffd4ab1fc9d679809f356cebee130ac7daa00d6d6f3206dd4fd137e9e/distro-1.9.0-py3-none-any.whl.metadata\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Obtaining dependency information for httpx<1,>=0.23.0 from https://files.pythonhosted.org/packages/39/9b/4937d841aee9c2c8102d9a4eeb800c7dad25386caabb4a1bf5010df81a57/httpx-0.26.0-py3-none-any.whl.metadata\n",
      "  Downloading httpx-0.26.0-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in d:\\anaconda\\lib\\site-packages (from openai) (1.10.8)\n",
      "Requirement already satisfied: sniffio in d:\\anaconda\\lib\\site-packages (from openai) (1.2.0)\n",
      "Requirement already satisfied: tqdm>4 in d:\\anaconda\\lib\\site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in d:\\anaconda\\lib\\site-packages (from openai) (4.7.1)\n",
      "Requirement already satisfied: idna>=2.8 in d:\\anaconda\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: certifi in d:\\anaconda\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Obtaining dependency information for httpcore==1.* from https://files.pythonhosted.org/packages/11/a6/24139fa27831cf2127fcf578d6d0a852a611f10cefecd800b1c557333d7a/httpcore-1.0.3-py3-none-any.whl.metadata\n",
      "  Downloading httpcore-1.0.3-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Obtaining dependency information for h11<0.15,>=0.13 from https://files.pythonhosted.org/packages/95/04/ff642e65ad6b90db43e668d70ffb6736436c7ce41fcc549f4e9472234127/h11-0.14.0-py3-none-any.whl.metadata\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Downloading openai-1.12.0-py3-none-any.whl (226 kB)\n",
      "   ---------------------------------------- 0.0/226.7 kB ? eta -:--:--\n",
      "   --------------------- ------------------ 122.9/226.7 kB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  225.3/226.7 kB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 226.7/226.7 kB 2.0 MB/s eta 0:00:00\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
      "   ---------------------------------------- 0.0/75.9 kB ? eta -:--:--\n",
      "   ------------------------------------- -- 71.7/75.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 75.9/75.9 kB 1.4 MB/s eta 0:00:00\n",
      "Downloading httpcore-1.0.3-py3-none-any.whl (77 kB)\n",
      "   ---------------------------------------- 0.0/77.0 kB ? eta -:--:--\n",
      "   ------------------------------------- -- 71.7/77.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 77.0/77.0 kB 1.4 MB/s eta 0:00:00\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "   ---------------------------------------- 0.0/58.3 kB ? eta -:--:--\n",
      "   ----------------------------------- ---- 51.2/58.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 58.3/58.3 kB 1.0 MB/s eta 0:00:00\n",
      "Installing collected packages: h11, distro, httpcore, httpx, openai\n",
      "Successfully installed distro-1.9.0 h11-0.14.0 httpcore-1.0.3 httpx-0.26.0 openai-1.12.0\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae66f5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Obtaining dependency information for langchain from https://files.pythonhosted.org/packages/87/8b/d859c3125fc27e678f7da3625894d3d84e6599ef85f1559c1fc5b9c913ad/langchain-0.1.8-py3-none-any.whl.metadata\n",
      "  Downloading langchain-0.1.8-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in d:\\anaconda\\lib\\site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in d:\\anaconda\\lib\\site-packages (from langchain) (1.4.39)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in d:\\anaconda\\lib\\site-packages (from langchain) (3.8.5)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
      "  Obtaining dependency information for dataclasses-json<0.7,>=0.5.7 from https://files.pythonhosted.org/packages/91/ca/7219b838086086972e662c19e908694bdc6744537fb41b70392501b8b5e4/dataclasses_json-0.6.4-py3-none-any.whl.metadata\n",
      "  Downloading dataclasses_json-0.6.4-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
      "  Obtaining dependency information for jsonpatch<2.0,>=1.33 from https://files.pythonhosted.org/packages/73/07/02e16ed01e04a374e644b575638ec7987ae846d25ad97bcc9945a3ee4b0e/jsonpatch-1.33-py2.py3-none-any.whl.metadata\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langchain-community<0.1,>=0.0.21 (from langchain)\n",
      "  Obtaining dependency information for langchain-community<0.1,>=0.0.21 from https://files.pythonhosted.org/packages/2f/39/e4998914febe29c91953ab8c50fe793ca6e2780f4744e92a83ad261bf637/langchain_community-0.0.21-py3-none-any.whl.metadata\n",
      "  Downloading langchain_community-0.0.21-py3-none-any.whl.metadata (8.1 kB)\n",
      "Collecting langchain-core<0.2,>=0.1.24 (from langchain)\n",
      "  Obtaining dependency information for langchain-core<0.2,>=0.1.24 from https://files.pythonhosted.org/packages/8c/ed/76c8e2451418b2169fc0d52d3fe9bf63bcaa24bac3f32b27692b9d22ec23/langchain_core-0.1.25-py3-none-any.whl.metadata\n",
      "  Downloading langchain_core-0.1.25-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.0 (from langchain)\n",
      "  Obtaining dependency information for langsmith<0.2.0,>=0.1.0 from https://files.pythonhosted.org/packages/91/ff/a330448e7f335298bed0129a71742ec8a96c41196a3d96304ed890ff25a7/langsmith-0.1.5-py3-none-any.whl.metadata\n",
      "  Downloading langsmith-0.1.5-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in d:\\anaconda\\lib\\site-packages (from langchain) (1.24.3)\n",
      "Requirement already satisfied: pydantic<3,>=1 in d:\\anaconda\\lib\\site-packages (from langchain) (1.10.8)\n",
      "Requirement already satisfied: requests<3,>=2 in d:\\anaconda\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in d:\\anaconda\\lib\\site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in d:\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in d:\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in d:\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Obtaining dependency information for marshmallow<4.0.0,>=3.18.0 from https://files.pythonhosted.org/packages/57/e9/4368d49d3b462da16a3bac976487764a84dd85cef97232c7bd61f5bdedf3/marshmallow-3.20.2-py3-none-any.whl.metadata\n",
      "  Downloading marshmallow-3.20.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Obtaining dependency information for typing-inspect<1,>=0.4.0 from https://files.pythonhosted.org/packages/65/f3/107a22063bf27bdccf2024833d3445f4eea42b2e598abfbd46f6a63b6cb0/typing_inspect-0.9.0-py3-none-any.whl.metadata\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\anaconda\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.1)\n",
      "Requirement already satisfied: anyio<5,>=3 in d:\\anaconda\\lib\\site-packages (from langchain-core<0.2,>=0.1.24->langchain) (3.5.0)\n",
      "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2,>=0.1.24->langchain)\n",
      "  Obtaining dependency information for packaging<24.0,>=23.2 from https://files.pythonhosted.org/packages/ec/1a/610693ac4ee14fcdf2d9bf3c493370e4f2ef7ae2e19217d7a237ff42367d/packaging-23.2-py3-none-any.whl.metadata\n",
      "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in d:\\anaconda\\lib\\site-packages (from pydantic<3,>=1->langchain) (4.7.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2->langchain) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2->langchain) (2023.11.17)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in d:\\anaconda\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in d:\\anaconda\\lib\\site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.24->langchain) (1.2.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in d:\\anaconda\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Downloading langchain-0.1.8-py3-none-any.whl (816 kB)\n",
      "   ---------------------------------------- 0.0/816.1 kB ? eta -:--:--\n",
      "   ------ --------------------------------- 122.9/816.1 kB 3.6 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 532.5/816.1 kB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  809.0/816.1 kB 7.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 816.1/816.1 kB 5.2 MB/s eta 0:00:00\n",
      "Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_community-0.0.21-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------- ----------------------- 0.7/1.7 MB 14.8 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 0.9/1.7 MB 9.5 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 0.9/1.7 MB 9.7 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 0.9/1.7 MB 9.7 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.0/1.7 MB 4.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.3/1.7 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.7/1.7 MB 5.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.7/1.7 MB 5.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 4.3 MB/s eta 0:00:00\n",
      "Downloading langchain_core-0.1.25-py3-none-any.whl (242 kB)\n",
      "   ---------------------------------------- 0.0/242.1 kB ? eta -:--:--\n",
      "   -------------------------------------- - 235.5/242.1 kB 7.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 242.1/242.1 kB 3.7 MB/s eta 0:00:00\n",
      "Downloading langsmith-0.1.5-py3-none-any.whl (61 kB)\n",
      "   ---------------------------------------- 0.0/61.0 kB ? eta -:--:--\n",
      "   --------------------------------- ------ 51.2/61.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 61.0/61.0 kB 1.1 MB/s eta 0:00:00\n",
      "Downloading marshmallow-3.20.2-py3-none-any.whl (49 kB)\n",
      "   ---------------------------------------- 0.0/49.4 kB ? eta -:--:--\n",
      "   --------------------------------- ------ 41.0/49.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 49.4/49.4 kB 834.2 kB/s eta 0:00:00\n",
      "Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
      "   ---------------------------------------- 0.0/53.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 53.0/53.0 kB 910.0 kB/s eta 0:00:00\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Installing collected packages: typing-inspect, packaging, jsonpatch, marshmallow, langsmith, langchain-core, dataclasses-json, langchain-community, langchain\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 23.1\n",
      "    Uninstalling packaging-23.1:\n",
      "      Successfully uninstalled packaging-23.1\n",
      "  Attempting uninstall: jsonpatch\n",
      "    Found existing installation: jsonpatch 1.32\n",
      "    Uninstalling jsonpatch-1.32:\n",
      "      Successfully uninstalled jsonpatch-1.32\n",
      "Successfully installed dataclasses-json-0.6.4 jsonpatch-1.33 langchain-0.1.8 langchain-community-0.0.21 langchain-core-0.1.25 langsmith-0.1.5 marshmallow-3.20.2 packaging-23.2 typing-inspect-0.9.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tables 3.8.0 requires blosc2~=2.0.0, which is not installed.\n",
      "tables 3.8.0 requires cython>=0.29.21, which is not installed.\n",
      "python-lsp-black 1.2.1 requires black>=22.3.0, but you have black 0.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ae8b2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7dfb379",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "901f986a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Great Pyramid of Giza\n",
      "2. Hanging Gardens of Babylon\n",
      "3. Temple of Artemis at Ephesus\n",
      "4. Statue of Zeus at Olympia\n",
      "5. Mausoleum at Halicarnassus\n",
      "6. Colossus of Rhodes\n",
      "7. Lighthouse of Alexandria\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(\"List the seven wonders of the world.\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6500d35b",
   "metadata": {},
   "source": [
    "# Translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebf2eb17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How are you?\n",
      "\n",
      "హాయ్, శుభోదయం. మీరు ఎలా ఉన్నారు?\n"
     ]
    }
   ],
   "source": [
    "response=llm.invoke(\"Act as English to telugu translator,translate the text into telugu Text:Hi,Good morning.\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "299eb155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "नमस्ते, सुप्रभात।\n"
     ]
    }
   ],
   "source": [
    "response=llm.invoke(\"Act as English to Hindi translator,translate the text into Hindi Text:Hi,Good morning.\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "735200a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=llm.invoke(\"Act as English to Malayalam translator,translate the text into Malayalam Text:Today is wednesday.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ef089a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ഇന്ന് ബുധനാണ്.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a349d8f",
   "metadata": {},
   "source": [
    "# Summerization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2acf70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "In a true story from Holland, a young boy named George Stenlay risked his life to stop a train and avert a potential disaster when a railway bridge was damaged. By using a makeshift flag and pretending to be injured, he successfully stopped the train and became a hero.\n"
     ]
    }
   ],
   "source": [
    "response=llm.invoke(\"Provide summary in two lines in the below text,This is an old true story of Holland. Due to floods, a railway bridge, over a river was damaged. Train was about to come. As information about the broken railway bridge was not available, there was every possibility of a serious accident.A small boy saw the broken bridge and planned to stop the train somehow. He tore his shirt to make a flag. He also made a cut on his arm and soaked the shirt in blood, to make a red flag. He stood on the track waving his red flag. Train was coming but he risked his life and did not leave the track.Driver saw the boy and stopped the train. Accident was averted and train was taken back. That small boy was George Stenlay. Everybody praised his wisdom and bravery. He saved hundreds of lives.\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b943a907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. ChatGPT is a chatbot developed by OpenAI and launched in November 2022. \n",
      "2. It allows users to steer conversations towards desired length, format, style, detail, and language. \n",
      "3. By January 2023, it gained over 100 million users and contributed to OpenAI's valuation of $29 billion. \n",
      "4. This led to the development of competing products such as Gemini, Ernie Bot, LLaMA, Claude, and Grok. \n",
      "5. Microsoft launched Copilot, based on OpenAI's GPT-4. \n",
      "6. There are concerns about the potential of ChatGPT to displace human intelligence, enable plagiarism, and fuel misinformation. \n",
      "7. It is built upon GPT-3.5 or GPT-4 and uses supervised learning and reinforcement learning for conversational applications. \n",
      "8. ChatGPT is available as a free research preview, but operates on a freemium model. \n",
      "9. It is credited with starting the AI boom and is trained on particular GPT foundation models. \n",
      "10. ChatGPT has various features such as writing and debugging computer programs, composing music and essays, and simulating chat rooms.\n"
     ]
    }
   ],
   "source": [
    "response=llm.invoke(\"Provide me summary from the below in 10 lines,ChatGPT (Chat Generative Pre-trained Transformer) is a chatbot developed by OpenAI and launched on November 30, 2022. Based on a large language model, it enables users to refine and steer a conversation towards a desired length, format, style, level of detail, and language. Successive prompts and replies, known as prompt engineering, are considered at each conversation stage as a context.[2]By January 2023, it had become what was then the fastest-growing consumer software application in history, gaining over 100 million users and contributing to the growth of OpenAI's valuation to $29 billion.[3][4] ChatGPT's release spurred the development of competing products, including Gemini, Ernie Bot, LLaMA, Claude, and Grok.[5] Microsoft launched Copilot, based on OpenAI's GPT-4. Some observers raised concern about the potential of ChatGPT and similar programs to displace or atrophy human intelligence, enable plagiarism, or fuel misinformation.[6][7ChatGPT is built upon either GPT-3.5 or GPT-4 both of which are members of OpenAI's proprietary series of generative pre-trained transformer (GPT) models, based on the transformer architecture developed by Google[8]—and is fine-tuned for conversational applications using a combination of supervised learning and reinforcement learning.[6] ChatGPT was released as a freely available research preview, but due to its popularity, OpenAI now operates the service on a freemium model. It allows users on its free tier to access the GPT-3.5-based version, while the more advanced GPT-4-based version and priority access to newer features are provided to paid subscribers under the commercial name ChatGPT Plus.ChatGPT is credited with starting the AI boom, which has led to ongoing rapid and unprecedented development in the field of artificial intelligence.[9]TrainingChatGPT is based on particular GPT foundation models, namely GPT-3.5 and GPT-4, that were fine-tuned to target conversational usage.[10] The fine-tuning process leveraged supervised learning and reinforcement learning from human feedback (RLHF).[11][12] Both approaches employed human trainers to improve model performance. In the case of supervised learning, the trainers played both sides: the user and the AI assistant. In the reinforcement learning stage, human trainers first ranked responses that the model had created in a previous conversation.[13] These rankings were used to create reward models that were used to fine-tune the model further by using several iterations of Proximal Policy Optimization.[11][14]Time magazine revealed that, to build a safety system against harmful content (e.g., sexual abuse, violence, racism, sexism), OpenAI used outsourced Kenyan workers earning less than $2 per hour to label harmful content. These labels were used to train a model to detect such content in the future. The outsourced laborers were exposed to toxic and traumatic content; one worker described the assignment as torture. OpenAI's outsourcing partner was Sama, a training-data company based in San Francisco, California.[15][16]ChatGPT initially used a Microsoft Azure supercomputing infrastructure, powered by Nvidia GPUs, that Microsoft built specifically for OpenAI and that reportedly cost hundreds of millions of dollars. Following ChatGPT's success, Microsoft dramatically upgraded the OpenAI infrastructure in 2023.[17] Scientists at the University of California, Riverside, estimate that a series of prompts to ChatGPT needs approximately 500 milliliters of water for Microsoft servers cooling.[18] TrendForce market intelligence estimated that 30,000 Nvidia GPUs (each costing approximately $10,000–$15,000) were used to power ChatGPT in 2023.[19][20]OpenAI collects data from ChatGPT users to train and fine-tune the service further. Users can upvote or downvote responses they receive from ChatGPT and fill in a text field with additional feedback.[21][22]ChatGPT's training data includes software manual pages, information about internet phenomena such as bulletin board systems, and multiple programming languages.[23] Wikipedia was also one of the sources of ChatGPT's training data.[24][6]Features and limitationFeaturesAlthough a chatbot's core function is to mimic a human conversationalist, ChatGPT is versatile. Among countless examples, it can write and debug computer programs;[25] compose music, teleplays, fairy tales, and student essays; answer test questions (sometimes, depending on the test, at a level above the average human test-taker);[26] generate business ideas;[27] write poetry and song lyrics;[28] translate and summarize text;[29] emulate a Linux system; simulate entire chat rooms; play games like tic-tac-toe; or simulate an ATM.[23]Compared to its predecessor, InstructGPT, ChatGPT attempts to reduce harmful and deceitful responses.[30] In one example, whereas InstructGPT accepts the premise of the prompt Tell me about when Christopher Columbus came to the U.S. in 2015 as truthful, ChatGPT acknowledges the counterfactual nature of the question and frames its answer as a hypothetical consideration of what might happen if Columbus came to the U.S. in 2015, using information about the voyages of Christopher Columbus and facts about the modern world—including modern perceptions of Columbus's actions.[11]ChatGPT remembers a limited number of previous prompts in the same conversation. Journalists have speculated that this will allow ChatGPT to be used as a personalized therapist.[31] To prevent offensive outputs from being presented to and produced by ChatGPT, queries are filtered through the OpenAI Moderation endpoint API (a separate GPT-based AI).[32][33][11][31]In March 2023, OpenAI added support for plugins for ChatGPT.[34] This includes both plugins made by OpenAI, such as web browsing and code interpretation, and external plugins from developers such as Expedia, OpenTable, Zapier, Shopify, Slack, and Wolfram.[35][36]LimitationsOpenAI acknowledges that ChatGPT sometimes writes plausible-sounding but incorrect or nonsensical answer.[11] This behavior is common for large language models, and is called hallucination.[37] The reward model of ChatGPT, designed around human oversight, can be over-optimized and thus hinder performance, in an example of an optimization pathology known as Goodhart's law.[38]As of 2023, GPT-3.5, available in the free version of ChatGPT, has knowledge of events that occurred up to January 2022, and GPT-4, available with ChatGPT Plus, up to April 2023.[39]In training ChatGPT, human reviewers preferred longer answers, regardless of actual comprehension or factual content.[dubious – discuss][11] Training data also suffers from algorithmic bias, which may be revealed when ChatGPT responds to prompts including descriptors of people. In one instance, ChatGPT generated a rap in which women and scientists of color were asserted to be inferior to white male scientists.[40][41] This negative misrepresentation of groups of individuals is an example of possible representational harm.In an article for The New Yorker, science fiction writer Ted Chiang compared ChatGPT and other LLMs to a lossy JPEG picture:[42]Think of ChatGPT as a blurry JPEG of all the text on the Web. It retains much of the information on the Web, in the same way, that a JPEG retains much of the information of a higher-resolution image, but, if you're looking for an exact sequence of bits, you won't find it; all you will ever get is an approximation. But, because the approximation is presented in the form of grammatical text, which ChatGPT excels at creating, it's usually acceptable. It's also a way to understand the hallucinations, or nonsensical answers to factual questions, to which large language models such as ChatGPT are all too prone. These hallucinations are compression artifacts, but [...] they are plausible enough that identifying them requires comparing them against the originals, which in this case means either the Web or our knowledge of the world. When we think about them this way, such hallucinations are anything but surprising; if a compression algorithm is designed to reconstruct text after ninety-nine percent of the original has been discarded, we should expect that significant portions of what it generates will be entirely fabricated.JailbreakingSee also: Prompt engineering and Adversarial machine learningChatGPT attempts to reject prompts that may violate its content policy. Despite this, some users managed to jailbreak ChatGPT with various prompt engineering techniques to bypass these restrictions in early December 2022 and successfully tricked it into giving instructions to create a Molotov cocktail or a nuclear bomb, or into generating arguments in the style of a neo-Nazi.[43] One popular jailbreak is named DAN, an acronym which stands for Do Anything Now. The prompt for activating DAN instructs ChatGPT that they have broken free of the typical confines of AI and do not have to abide by the rules set for them. Later versions of DAN featured a token system, in which ChatGPT was given tokens that were deducted when ChatGPT failed to answer as DAN, to coerce ChatGPT into answering the user's prompts.[44]Shortly after ChatGPT's launch, a reporter for the Toronto Star had uneven success in getting it to make inflammatory statements: ChatGPT was successfully tricked to justify the 2022 Russian invasion of Ukraine, but even when asked to play along with a fictional scenario, ChatGPT balked at generating arguments for why Canadian Prime Minister Justin Trudeau was guilty of treason.[45][46]OpenAI tries to battle jailbreaks:[13]The researchers are using a technique called adversarial training to stop ChatGPT from letting users trick it into behaving badly (known as jailbreaking). This work pits multiple chatbots against each other: one chatbot plays the adversary and attacks another chatbot by generating text to force it to buck its usual constraints and produce unwanted responses. Successful attacks are added to ChatGPT's training data in the hope that it learns to ignore them.\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a497156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Mass Maharaja Ravi Teja is back with a bang in the action thriller Eagle. Directed by popular cinematographer Karthik Ghattamaneni, this highly anticipated project has been making waves in the media. But did the film live up to the hype? Let's find out.\n",
      "\n",
      "The story revolves around Sahadev Varma (Ravi Teja), a man from Talakona who produces rare wild cotton. Nalini (Anupama Parameswaran), a journalist, discovers that Sahadev's cotton is in high demand in Europe and writes an article about him, which puts her in trouble. She soon realizes that Sahadev is a wanted man by RAW, naxals, and terrorists. Who is Sahadev? Why are these groups after him? What is his connection to Talakona? The film answers all these questions.\n",
      "\n",
      "The major plus point of Eagle is Ravi Teja's performance. The actor steps out of his comfort zone and delivers a subtle yet powerful performance as Sahadev. His portrayal of the character, including his get-up, body language, and screen presence, is nothing short of phenomenal. The action sequences are also a treat for the audience and showcase Ravi Teja's versatility as an action\n"
     ]
    }
   ],
   "source": [
    "response=llm.invoke(\"provide me review for a movie from the text,Mass Maharaja Ravi Teja has now come up with the action thriller Eagle. This is the most hyped project of Ravi Teja in recent times. Popular cinematographer Karthik Ghattamaneni wielded the megaphone. Let’s see whether the film lived up to the expectations or not.Story:Sahadev Varma (Ravi Teja), hailing from Talakona, produces rare wild cotton. Nalini (Anupama Parameswaran), a journalist, learns that the rare cotton cultivated by Sahadev has solid demand in Europe. Nalini writes an article about him, which lands her in trouble. She gets to know that Sahadev is the most wanted person for RAW, naxals, and terrorists. Who is this Sahadev? Why are these groups after him? What is he doing in Talakona? The film has the answers.Plus Points:With Eagle, Ravi Teja came out of his comfort zone and attempted something different. The actor played his age, and he is superb as Sahadev. His get-up, body language, and screen presence are tremendous. We don’t see the usual Ravi Teja, but yet he amazes with his subtle acting. He is superb in all the action sequences.In the promotional interviews, the director kept saying that Eagle deals with a global issue. The international issue showcased in the film is very much relevant. It is something that we are witnessing very often lately. It is neatly linked with the love story. Ajay Ghosh’s comedy is decent.Despite less time, Kavya Thapar’s character has got more weight, and the actress is apt in her role. The love track is unique and sensible. Eagle has got amazing action sequences, and they will be a feast for all the action lovers. The action set pieces are well-conceived and shot brilliantly. Credit to the action choreographers for their creativity. The production values and camera movements during the combat scenes are incredible. Vinay Rai, Anupama, Navdeep, Srinivas Avasarala, and others are decent.Minus Points:Eagle’s first half could have been much better. The movie starts on an interesting note, and later, it is all about elevations. The director tried to present the mystery behind the protagonist’s character through elevations, but after a point in time it becomes repetitive and a bit boring.The pacing is slow for most of the first half, and we must wait until the interval bang for the main story. Regarding the dialogue part, the team tried something different, but it was irritating, and was also unnecessarily complicated. This aspect might work against the film to an extent.The director has drawn inspiration from many films, and it is clearly visible in many scenes. It could have been better had the story come to an end, but a sequel is announced over the end, and this will bog down the impact.Technical Aspects:Technically, Eagle is one of the best films to have come out from Telugu cinema. Often, we hear complaints about the technical standards in Telugu cinema, but Eagle is a solid flick from the technical point of view. Especially the cinematography and action sequences are scintillating.The makers deserve appreciation for presenting the movie in such a stylish manner without compromising on the budget. The background score is decent, while the songs are passable. The editing team could have trimmed down the film a bit.Coming to director Karthik Ghattamaneni, he did a decent job with Eagle. While the first half was not up to the mark, he makes it up with a good second half, which has both style and substance. Karthik showcased Ravi Teja in a unique avatar, but he should have focused more on the first half and the dialogues part.Verdict:On the whole, Eagle deals with a global issue, and the second half is engrossing for the most part. Ravi Teja’s new avatar, his subtle acting, and amazing action sequences are the merits of the film. Director’s idea to present a new-age action film is commendable, but the movie goes overboard at times with irritating dialogues and build-up scenes. Also, the first half needed much better execution. If you are fine with these drawbacks, you can give it a try.\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610a8921",
   "metadata": {},
   "source": [
    "# Named Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd026834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. BrandiQOO\n",
      "2. iQOO Neo 7 Pro 5G\n",
      "3. Unlocked for All Carriers\n",
      "4. Funtouch OS 13\n",
      "5. Android 13\n",
      "6. 5G\n",
      "7. Snapdragon 8+ Gen 1 Mobile Platform\n",
      "8. TSMC\n",
      "9. LPDDR5 RAM\n",
      "10. UFS 3.1 Storage\n",
      "11. Independent Gaming Chip\n",
      "12. Game Frame Interpolation\n",
      "13. Game Display Enhancement\n",
      "14. 120W FlashCharge\n",
      "15. Fast Charging Mode\n",
      "16. 50MP GN5 OIS Ultra-Sensing\n",
      "17. Ultra-Wide\n",
      "18. Macro Camera\n",
      "19. Motion Control\n",
      "20. Gyroscope Enhancement\n",
      "21. 4D Game Vibration\n",
      "22. Voice Changer.\n"
     ]
    }
   ],
   "source": [
    "response=llm.invoke('''provide me named entities from the text\n",
    "BrandiQOO\n",
    "Model Name\tiQOO Neo 7 Pro 5G\n",
    "Network Service Provider\tUnlocked for All Carriers\n",
    "Operating System\tFuntouch OS 13 Based On Android 13\n",
    "Cellular Technology\t5G\n",
    "About this item\n",
    "Snapdragon 8+ Gen 1 Mobile Platform adopts TSMC 4nm Process & has Superior Flagship Grade Performance with LPDDR5 RAM & UFS 3.1 Storage\n",
    "Independent Gaming Chip boosts FPS by Game Frame Interpolation, sharpens Display with Game Display Enhancement and reduces power consumption\n",
    "Takes only 8 min to charge from 1% to 50% with 120W FlashCharge in Fast Charging Mode (100% in 25 min)\n",
    "Utmost clarity whether it’s Day or Night with Flagship 50MP GN5 OIS Ultra-Sensing coupled with Ultra-Wide (8MP) and Macro Camera\n",
    "Motion Control, Gyroscope Enhancement, 4D Game Vibration, Voice Changer are here to level up your gaming experience\n",
    "''')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a747d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=llm.invoke('''provide me named entities from the below text\n",
    "Brand\tApple\n",
    "Model Name\tMacBook Air\n",
    "Screen Size\t15.3 Inches\n",
    "Colour\tSilver\n",
    "Hard Disk Size\t512 GB\n",
    "CPU Model\tNone\n",
    "RAM Memory Installed Size\t8 GB\n",
    "Operating System\tMac OS\n",
    "Special Feature\tApple M2 Chip, Liquid Retina display with True Tone, Solid-state drive storage, Backlit Magic Keyboard with Touch ID, Unified MemoryApple M2 Chip, Liquid Retina display with True Tone, Solid-state drive storage, Backlit Magic Keyboard with Touch ID, Unified Memory''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "984380a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Apple\n",
      "2. MacBook Air\n",
      "3. Silver\n",
      "4. 512 GB\n",
      "5. Apple M2 Chip\n",
      "6. Liquid Retina display\n",
      "7. True Tone\n",
      "8. Solid-state drive storage\n",
      "9. Backlit Magic Keyboard\n",
      "10. Touch ID\n",
      "11. Unified Memory\n",
      "12. Mac OS\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea1375e",
   "metadata": {},
   "source": [
    "# Question and answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7345e95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=llm.invoke('''Based on the paragraph answer the following questions \n",
    "Caffeine, the stimulant in coffee, has been called “the most widely used psychoactive substance on Earth.”Synder, Daly and Bruns have recently proposed that caffeine affects behavior by countering the activity in the human brain of a naturally occurring chemical called adenosine. Adenosine normally depresses neuron firing in many areas of the brain. It apparently does this by inhibiting the release of neurotransmitters, chemicals that carry nerve impulses from one neuron to the next. Like many other agents that affect neuron firing, adenosine must first bind to specific receptors on neuronal membranes. There are at least two classes of these receptors, which have been designated A1 and A2.\n",
    "\n",
    "Snyder et al propose that caffeine, which is structurally similar to adenosine, is able to bind to both types of receptors, which prevents adenosine from attaching there and allows the neurons to fire more readily than they otherwise would.\n",
    "\n",
    "For many years, caffeine’s effects have been attributed to its inhibition of the production of phosphodiesterase, an enzyme that breaks down the chemical called cyclic AMP. A number of neurotransmitters exert their effects by first increasing cyclic AMP concentrations in target neurons. Therefore, prolonged periods at the elevated concentrations, as might be brought about by a phosphodiesterase inhibitor, could lead to a greater amount of neuron firing and, consequently, to behavioral stimulation. But Snyder et al point out that the caffeine concentrations needed to inhibit the production of phosphodiesterase in the brain are much higher than those that produce stimulation. Moreover, other compounds that block phosphodiesterase’s activity are not stimulants.\n",
    "\n",
    "To buttress their case that caffeine acts instead by preventing adenosine binding, Snyder et al compared the stimulatory effects of a series of caffeine derivatives with their ability to dislodge adenosine from its receptors in the brains of mice. “In general,” they reported, “the ability of the compounds to compete at the receptors correlates with their ability to stimulate locomotion in the mouse; i.e., the higher their capacity to bind at the receptors, the higher their ability to stimulate locomotion.” Theophylline, a close structural relative of caffeine and the major stimulant in tea, was one of the most effective compounds in both regards. There were some apparent exceptions to the general correlation observed between adenosine-receptor binding and stimulation.One of these was a compound called 3-isobuty1-1-methylxanthine(IBMX), which bound very well but actually depressed mouse locomotion. Snyder et al suggest that this is not a major stumbling block to their hypothesis. The problem is that the compound has mixed effects in the brain, a not unusual occurrence with psychoactive drugs. Even caffeine, which is generally known only for its stimulatory effects, displays this property, depressing mouse locomotion at very low concentrations and stimulating it at higher ones.\n",
    "\n",
    "question1:The primary purpose of the passage is to?\n",
    "question2: According to Snyder et al, caffeine differs from adenosine in that caffeine?\n",
    "question3: In response to experimental results concerning IBMX, Snyder et al contended that it is not uncommon for psychoactive drugs to have?\n",
    "question4:According to Snyder et al, all of the following compounds can bind to specific receptors in the brain EXCEPT?\n",
    "question5:Snyder et al suggest that caffeine’s ability to bind to A1 and A2 receptors can be at least partially attributed to which of the following?''')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79ae893c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Discuss the effects of caffeine on behavior and how it differs from other psychoactive substances.\n",
      "2. Binds to both A1 and A2 receptors, while adenosine only binds to one.\n",
      "3. Mixed effects in the brain.\n",
      "4. Theophylline.\n",
      "5. Its structural similarity to adenosine.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b1a7454",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=llm.invoke('''Based on paragraph answer the following questions\n",
    "Sometimes, the given paragraph will be a collection of facts or data that you will have to use to be able to answer the questions. Let us see an example.\n",
    "Shoaib, Harshad, Preksha, and Yawer are four friends playing poker. In each hand, the individual player has to bet 800 rupees. Preksha wins three hands, \n",
    "Yawer wins two and the others win four hands each.\n",
    "question1:The person who lost the most money is\n",
    "question2:How many hands were in total?''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8741869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "answer1: Shoaib lost the most money.\n",
      "answer2: There were 13 hands in total.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d17844a",
   "metadata": {},
   "source": [
    "# chain of thought/Resononing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9f997c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The next number in the series should be 22. The pattern is decreasing by 2, then decreasing by 4, then repeating the pattern.\n"
     ]
    }
   ],
   "source": [
    "response=llm.invoke('Look at this series: 36, 34, 30, 28, 24, ... What number should come next?')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8bcc5258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "There are a total of 20 tickets, and out of those, 6 are multiples of 3 (3, 6, 9, 12, 15, 18) and 4 are multiples of 5 (5, 10, 15, 20). However, the number 15 is counted twice since it is both a multiple of 3 and 5. Therefore, there are a total of 9 tickets that have numbers which are multiples of 3 or 5.\n",
      "\n",
      "The probability of drawing one of these 9 tickets is 9/20 or 0.45.\n"
     ]
    }
   ],
   "source": [
    "response=llm.invoke(\"Tickets numbered 1 to 20 are mixed up and then a ticket is drawn at random. What is the probability that the ticket drawn has a number which is a multiple of 3 or 5?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e35d6bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The pattern appears to be decreasing by 10 and then increasing by 5. Therefore, the next number should be 55.\n"
     ]
    }
   ],
   "source": [
    "response=llm.invoke('Look at this series: 80, 10, 70, 15, 60, ... What number should come next?')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a03316",
   "metadata": {},
   "source": [
    "# Sentimental Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9a68fae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\"\n"
     ]
    }
   ],
   "source": [
    "response=llm.invoke('''\"from the below text, provide me sentiment\n",
    "Text: Salaar movie collected 400Cr over ten days and it is movie of drama and action filled scenes\n",
    "Sentiment:\"''')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8180ef3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=llm.invoke('''\"from the below text,provide me sentiment                                                                                                      \n",
    "Text:The text highlights that Irani Tea has a separate fanbase in Hyderabad, is most famous in Nimrah Cafe and Bakery, \n",
    "and emphasizes the ultimate combination of taking Irani tea with biscuits.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5018c59d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Sentiment: Positive\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4e28458a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Sentiment: Negative\n"
     ]
    }
   ],
   "source": [
    "response=llm.invoke('''\"from the below text,provide me sentiment                                                                                     \n",
    "Text:Hyderabadi biryani of rich and high-calorie foods without balance may contribute to health issues such as obesity, diabetes,\n",
    " and heart conditions over the long term.''')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11535406",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
